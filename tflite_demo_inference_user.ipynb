{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from avato import Client\n",
    "from avato import Secret\n",
    "from avato_tflite_dynamic import TFLITEDYNAMIC_Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login to avato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_user_client = Client(\n",
    "    username=os.environ[\"INFERENCE_USER_ID\"],\n",
    "    password=os.environ[\"INFERENCE_USER_PASSWORD\"],\n",
    "    instance_types=[TFLITEDYNAMIC_Instance],\n",
    "    backend_host=\"avato-staging.westeurope.cloudapp.azure.com\",\n",
    "    backend_port=\"15005\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get TFLite instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the inference user would be given the instance id\n",
    "# by the model owner.\n",
    "INSTANCE_ID = \"c72b5008bc1d2e36ca2102d5f730eccb553e7a770f3b49c4dae16499126ecd22\"\n",
    "inference_user_instance = inference_user_client.get_instance(\n",
    "    INSTANCE_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check security guarantees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# The inference user performs the same security\n",
    "# checks that the owner did\n",
    "inference_user_instance.validate_fatquote(\n",
    "    expected_measurement=\"fd424f1251f75b48a5e23e6e8c390c9f919ff250de2c1a75218b6685b23a59b4\",\n",
    "    accept_debug=True,\n",
    "    accept_group_out_of_date=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating (randomly) a public-private keypair and setting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_user_secret = Secret()\n",
    "inference_user_instance.set_secret(inference_user_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the model format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelSha256: \"!\\214\\373(\\213\\203K\\324r\\273\\256\\2402a\\333o~\\033\\\\\\310\\342\\263\\201K\\355\\332\\t\\232M\\025\\017>\"\n",
      "modelSize: 408612\n",
      "arenaSize: 131072\n",
      "inputTensorFormats {\n",
      "  dimensions: 1\n",
      "  dimensions: 28\n",
      "  dimensions: 28\n",
      "  valueType: \"float32le\"\n",
      "  size: 3136\n",
      "}\n",
      "outputTensorFormats {\n",
      "  dimensions: 1\n",
      "  dimensions: 10\n",
      "  valueType: \"float32le\"\n",
      "  size: 40\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Some relevant fields explained in more detail:\n",
    "# `modelSha256`: Provides a hash of the executed remote model. This adds some notion of identity.\n",
    "#  `inputTensorFormats`: Format of the input tensors.\n",
    "#  `outputTensorFormats`: Format of the output tensors.\n",
    "model_format = inference_user_instance.get_model_format()\n",
    "print(model_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote - Label: 9 with weight: 0.9994888305664062\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Import the Fashion MNIST dataset.\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(_, _), (test_images, _) = fashion_mnist.load_data()\n",
    "# Preprocess the data: Data normalization.\n",
    "test_images = test_images / 255.0\n",
    "test_image = test_images[0:1, :, :]\n",
    "\n",
    "\n",
    "# Make a prediction using the model running in the secure enclave\n",
    "prediction_remote = inference_user_instance.predict(test_image)\n",
    "print(\n",
    "    f\"Remote - Label: {prediction_remote.argmax()} with weight: {prediction_remote.max()}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
